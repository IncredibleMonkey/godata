{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Softmax Classification은 0,1 만이 아니라 1, 2, 3, 4 등 여러개의 분류 값을 예측하는데 사용된다.<br>\n",
    "\n",
    "결과값에 softmax라는 함수를 적용하면 예측값이 1일 확률, 2일 확률, ... 등등으로 나온다.<br>\n",
    "(다중분류에서는 단일분류에서와 다르게 sigmoid 함수를 적용하지 않는다. sigmoid가 들어갈 자리에 softmax 함수가 들어가는 것이다.)<br>\n",
    "\n",
    "그 모든 확률을 더하면 1이 된다.<br>\n",
    "물론 각 예측값의 확률들을 \"A\", \"B\", \"C\"와 같은 형태로 표현할 수도 있다.!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8분 40초 코드  따라하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [[1, 2, 1, 1] ,[2, 1, 3, 2],[3, 1, 3, 4],[4, 1, 5, 5],[1, 7, 5, 5],\n",
    "                                                      [1, 2, 5, 6], [1, 6, 6, 6], [1, 7, 7, 7]]\n",
    "y_data = [[0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 1, 0], [0, 1, 0], [0, 1, 0], [1, 0, 0], [1, 0, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(\"float\", [None,4])\n",
    "Y = tf.placeholder(\"float\", [None,3])\n",
    "nb_clasees = 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np_classes는 분류하고자 하는 값의 종류가 3개라고 명시적으로 표현한 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_normal([4, nb_clasees]), name='weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "행렬곱 WX형태로 나타낼거니까 4를 앞에 적어주는거다! 헷갈리지 말자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = tf.Variable(tf.random_normal([nb_clasees]), name='bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "corss entropy라는 코드이다.<br> 수식의 생김은 다르지만 효과는 \"ylog(Hypothesis) - (1-y)log(1-Hypothesis)와 같다.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 7.3804965\n",
      "200 0.7406758\n",
      "400 0.6226485\n",
      "600 0.580573\n",
      "800 0.5498733\n",
      "1000 0.52552235\n",
      "1200 0.5054265\n",
      "1400 0.48834983\n",
      "1600 0.47350156\n",
      "1800 0.4603525\n",
      "2000 0.4485355\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(2001):\n",
    "        sess.run(optimizer, feed_dict={X: x_data, Y: y_data})\n",
    "        if step % 200 == 0:\n",
    "            print(step, sess.run(cost, feed_dict={X: x_data, Y: y_data}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 분류된 값 확인하기\n",
    "분류된 값은 ~가 될 확률로 표현된다.<br>\n",
    "아래 코드에는 분류되는 값을 3개로 표현했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.4840766e-07 1.0987824e-03 9.9890029e-01]] [2]\n"
     ]
    }
   ],
   "source": [
    "a = sess.run(hypothesis, feed_dict={X: [[1, 3, 4, 3]]})\n",
    "print(a, sess.run(tf.argmax(a, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각각 분류될 확률이 [3,0]형태로 표현됐다.<br>\n",
    "첫번째는 0.0000009, 두번째는 0.001 , 세번째는 0.9이다.<br>\n",
    "리스트자료 맨 뒤에는 [2]라고 적혀있는데 이것은 세번째 값(파이썬은 0부터 숫자를 센다.)이 채택됐음을 말한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
